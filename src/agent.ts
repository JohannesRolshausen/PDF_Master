import * as dotenv from "dotenv";
dotenv.config();

import { ChatGoogleGenerativeAI } from "@langchain/google-genai";
import { StateGraph, MessagesAnnotation } from "@langchain/langgraph";
import { ToolNode } from "@langchain/langgraph/prebuilt";
import { pdfCutterTool } from "./tools.js";
import { HumanMessage } from "@langchain/core/messages";

// 1. Das Model Setup (Gemini Pro)
const tools = [pdfCutterTool];
const toolNode = new ToolNode(tools); // Vorgefertigter Node, der Tools ausfÃ¼hrt

const model = new ChatGoogleGenerativeAI({
  model: "gemini-flash-lite-latest",
  temperature: 0,
}).bindTools(tools);

// 2. Definition der Logik fÃ¼r den Agent-Node
// Der Agent bekommt den State (Nachrichten), ruft das Model auf und gibt neue Nachrichten zurÃ¼ck
async function callModel(state: typeof MessagesAnnotation.State) {
  const { messages } = state;
  const result = await model.invoke(messages);
  return { messages: [result] };
}

// 3. Entscheidungslogik (Conditional Edge)
// Soll das Tool ausgefÃ¼hrt werden oder antworten wir dem User?
function shouldContinue(state: typeof MessagesAnnotation.State) {
  const { messages } = state;
  const lastMessage = messages[messages.length - 1];

  // Wenn das LLM einen Tool-Call generiert hat, gehen wir zu "tools"
  if (
    "tool_calls" in lastMessage && 
    Array.isArray(lastMessage.tool_calls) && 
    lastMessage.tool_calls.length > 0
  ) {
    return "tools";
  }
  
  // Sonst sind wir fertig
  return "__end__";
}

// 4. Den Graphen zusammenbauen
const workflow = new StateGraph(MessagesAnnotation)
  .addNode("agent", callModel)
  .addNode("tools", toolNode)
  .addEdge("__start__", "agent") // Start -> Agent
  .addConditionalEdges("agent", shouldContinue) // Agent -> Entscheidung
  .addEdge("tools", "agent"); // Tools -> ZurÃ¼ck zum Agent (Ergebnis interpretieren)

// Kompilieren des Graphen zu einer ausfÃ¼hrbaren App
export const app = workflow.compile();


export async function runAgentWorkflow(pdfPath: string, instruction: string): Promise<string> {
  // 1. Inputs fÃ¼r den Graphen vorbereiten
  
  console.log(`ğŸ¤– Agent startet...`);
  console.log(`ğŸ“‚ Zieldatei: ${pdfPath}`);
  console.log(`ğŸ“ Aufgabe: ${instruction}\n`);

  const inputs = {
    messages: [
      new HumanMessage(
        `Hier ist der Dateipfad: "${pdfPath}". ` +
        `Aufgabe: ${instruction}. ` +
        `Output-Verzeichnis ist dasselbe wie Quellverzeichnis. ` +
        `Antworte am Ende NUR mit dem Pfad zur neuen Datei oder einer Fehlermeldung.`
      ),
    ],
  };
  // 2. Graphen ausfÃ¼hren
  // Wir nutzen 'invoke' statt 'stream', da der MCP Server auf das finale Ergebnis wartet
  const result = await app.invoke(inputs);
  
  // 3. Die letzte Nachricht (die Antwort des Agenten) extrahieren
  const lastMessage = result.messages[result.messages.length - 1];
  
  return lastMessage.content as string;
}